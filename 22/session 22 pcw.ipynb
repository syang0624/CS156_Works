{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fc/g11j1bt552j3dc6g0ngw41hh0000gn/T/ipykernel_7103/2157740809.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mtrans_mat_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransition_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang_A_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0mtrans_mat_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransition_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang_B_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0mtrans_mat_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransition_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang_C_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/fc/g11j1bt552j3dc6g0ngw41hh0000gn/T/ipykernel_7103/2157740809.py\u001b[0m in \u001b[0;36mtransition_matrix\u001b[0;34m(samples)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatted_transitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# create a new column, shifting the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'shift'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;31m# add a count column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "'''\n",
    "The code was adapted from the documentation of sklearn\n",
    "'''\n",
    "paths = glob('text.txt/*')\n",
    "\n",
    "lang_keys = ['A', 'B', \"C\"]\n",
    "lang_paths = []\n",
    "test_paths = []\n",
    "\n",
    "for lang in lang_keys:\n",
    "    lang_paths.append(list(filter(re.compile(f'.*lang{lang}').match, paths)))\n",
    "lang_A, lang_B, lang_C = lang_paths\n",
    "\n",
    "test_paths.append(list(filter(re.compile('.*test').match, paths)))\n",
    "\n",
    "def read_data(paths):\n",
    "    all_data = []\n",
    "    for path in paths:\n",
    "        with open(path) as f:\n",
    "            all_data.append(f.readlines())\n",
    "    return all_data\n",
    "\n",
    "lang_A_data = read_data(lang_A)\n",
    "lang_B_data = read_data(lang_B)\n",
    "lang_C_data = read_data(lang_C)\n",
    "test_data = read_data(test_paths[0])\n",
    "\n",
    "def initial_distribution(samples):\n",
    "    formatted_data = sum(samples, [])\n",
    "    first_data = [string[0] for string in formatted_data]\n",
    "    counts = dict(Counter(first_data))\n",
    "    total = sum(counts.values())\n",
    "\n",
    "    initial_dist = {key: value/total for key, value in counts.items()}\n",
    "    return initial_dist\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(list(''.join(sum(lang_A_data, []))))\n",
    "mapping = dict(zip(list(le.classes_), [i for i in range(0, len(le.classes_))]))\n",
    "\n",
    "\n",
    "def transition_matrix(samples):\n",
    "    formatted_transitions = list(''.join(sum(samples, [])))\n",
    "    le.transform(formatted_transitions)\n",
    "\n",
    "    df = pd.DataFrame(formatted_transitions)\n",
    "    # create a new column, shifting the data\n",
    "    df['shift'] = df[0].shift(-1)\n",
    "    # add a count column\n",
    "    df['count'] = 1\n",
    "    trans_matrix = df.groupby([0, 'shift']).count().unstack().fillna(0)\n",
    "    # normalisation step\n",
    "    norm_trans_matrix = trans_matrix.div(trans_matrix.sum(axis=1), axis=0).values\n",
    "    norm_trans_matrix[np.where(norm_trans_matrix == 0)] = 0.001\n",
    "    return norm_trans_matrix\n",
    "\n",
    "\n",
    "trans_mat_a = transition_matrix(lang_A_data)\n",
    "trans_mat_b = transition_matrix(lang_B_data)\n",
    "trans_mat_c = transition_matrix(lang_C_data)\n",
    "\n",
    "prior_probs = {\"A\": 0.3333, \"B\": 0.3333, \"C\": 0.3333}\n",
    "\n",
    "def markov_likelihood(test_string, transition_matrix):\n",
    "    total_prob = 1\n",
    "    for char_idx in range(len(test_string)-1):\n",
    "        prob = transition_matrix[mapping.get(test_string[char_idx])][mapping.get(test_string[char_idx+1])]\n",
    "        total_prob *= np.log(prob)\n",
    "    return total_prob\n",
    "\n",
    "def marginalization(test_string):\n",
    "    marginal = (\n",
    "    markov_likelihood(test_string, trans_mat_a)*prior_probs.get(\"A\") *\n",
    "    markov_likelihood(test_string, trans_mat_b)*prior_probs.get(\"B\") *\n",
    "    markov_likelihood(test_string, trans_mat_c)*prior_probs.get(\"C\")\n",
    "    )\n",
    "    return marginal\n",
    "\n",
    "def bayes(test_string, transition_matrix, language):\n",
    "    likelihood = markov_likelihood(test_string, transition_matrix)\n",
    "    prior = prior_probs.get(language)\n",
    "    marginal = marginalization(test_string)\n",
    "\n",
    "    norm = likelihood / marginal\n",
    "\n",
    "    return norm * prior\n",
    "\n",
    "def bayesianify_test_data(tests):\n",
    "    test_case_probs = []\n",
    "    for string in processed_test_data:\n",
    "        lang_probs = []\n",
    "        lang_probs.append( bayes(string, trans_mat_a, \"A\") )\n",
    "        lang_probs.append( bayes(string, trans_mat_b, \"B\") )\n",
    "        lang_probs.append( bayes(string, trans_mat_c, \"C\") )\n",
    "\n",
    "        test_case_probs.append(lang_probs)\n",
    "    return test_case_probs\n",
    "\n",
    "processed_test_data = sum(test_data, [])\n",
    "\n",
    "output = bayesianify_test_data(processed_test_data)\n",
    "\n",
    "lang_array = [\"A\", \"B\", \"C\"]\n",
    "\n",
    "for testcase in output:\n",
    "    idx = np.argmax(testcase)\n",
    "    print(f\"Language {lang_array[idx]} is the most probable\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
