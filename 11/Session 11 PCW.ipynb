{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-class work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Maximum Likelihood Estimation of a Bernoulli Distribution\n",
    "\n",
    "Suppose we have a random sample X<sub>1</sub>, X<sub>2</sub>, ..., X<sub>n</sub> where:\n",
    "\n",
    "- X<sub>i</sub> = 0 if a randomly selected student does not eat meat, and\n",
    "- X<sub>i</sub> = 1 if a randomly selected student does eat meat.\n",
    "\n",
    "Assuming that the X<sub>i</sub> are independent Bernoulli random variables with unknown parameter p, derive the maximum likelihood estimator of p, the proportion of students who eat meat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the series $X_1, X_2, X_3,\\ldots X_n$ represent the indicator variable value for all n students. Then the Bernoulli probability of observing each outcomes would then be $p^{X_i}\\times (1-p)^{1-X_i}$ based on the formula provided in the textbook. The overall likelihood of all of these given a chosen p $p(data | p)$ would then be the product of all of the probabilities.\n",
    "Thus, $$P(data | p) = \\prod_{i}{p^{X_i}\\times (1-p)^{1-X_i}}$$\n",
    "Logarithms of this will preserve the increasing sequence of the likelihoo. Therefore, we can take the log to convert the product to a sum. This gives: $$\\log(P(data | p)) = \\sum_{i}{X_i\\log(p)+(1-X_i)\\log(1-p)}$$\n",
    "\n",
    "Differentiate on this to find maxima:\n",
    "$$\\frac{\\delta}{\\delta p}(\\log(P(data | p))) = \\sum_{i}{\\frac{\\delta}{\\delta p}(X_i\\log(p)) + \\frac{\\delta}{\\delta p}(1-X_i)\\log(1-p)}$$\n",
    "$$\\frac{\\delta}{\\delta p}(\\log(P(data | p))) = \\sum_{i}{\\frac{X_i}{p} + \\frac{X_i-1}{1-p}} = \\sum_{i}{\\frac{X_i}{p} + \\frac{X_i-1}{1-p}} = \\sum_{i}{\\frac{X_i - p}{p(1-p)}}$$\n",
    "Since it's the maxima, this value should be equal to 0, $\\sum_{i}{X_i - p} = 0$. This tells us that p is equal to the mean of the data as $pN = \\sum_{i}{X_i}$ and so the maximum likelihood estimate of p is the mean of our data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Maximum Likelihood Estimation for a Normal Distribution\n",
    "\n",
    "Derive the maximum likelihood estimate for a group of observations that is normally distributed, but with unknown mean and variance. How does the maximum likelihood estimate compare to the standard estimates of an unknown mean and variance?\n",
    "\n",
    "For these questions, make sure your answers are uploaded to your personal repository <b>before</b> the start of class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability for the normal distribution, $$P(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^{2}}$$\n",
    "\n",
    "Given that the maximum likelihood estimate given a set of observed data $X_1, X_2, X_3,\\ldots X_n$ would be equal to the product of all of them $P(X_i | \\sigma, \\mu)$. $$P(data | \\sigma, \\mu) = \\prod_{i}{\\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}(\\frac{x_i-\\mu}{\\sigma})^{2}}} = (\\frac{1}{\\sigma\\sqrt{2\\pi}})^n\\times e^{-\\frac{1}{2}\\sum_{i}{(\\frac{x_i-\\mu}{\\sigma})^{2}}} = (\\frac{1}{\\sigma\\sqrt{2\\pi}})^n\\times e^{-\\frac{1}{2}\\sum_{i}{\\frac{x_i^2-2x\\mu + \\mu^2}{\\sigma^2}}} = (\\frac{1}{\\sigma\\sqrt{2\\pi}})^n\\times e^{(-\\sum_{i}{\\frac{x_i^2}{2\\sigma^2}}+\\mu\\sum_{i}{\\frac{x_i}{\\sigma^2}} - \\frac{n\\mu^2}{2\\sigma^2})}$$ Taking the differential with regards to the mean then yields: $$\\frac{\\delta}{\\delta \\mu}P(data | \\sigma, \\mu) = (\\frac{1}{\\sigma\\sqrt{2\\pi}})^n\\times\\frac{\\delta}{\\delta \\mu}e^{(-\\sum_{i}{\\frac{x_i^2}{2\\sigma^2}}+\\sum_{i}{\\frac{x_i\\mu}{2\\sigma^2}} - \\frac{n\\mu^2}{2\\sigma^2})} = (\\frac{1}{\\sigma\\sqrt{2\\pi}})^n\\times(\\sum_{i}{\\frac{x_i}{\\sigma^2}} - \\frac{2n\\mu}{2\\sigma^2})\\times e^{-\\frac{1}{2}\\sum_{i}{(\\frac{x_i-\\mu}{\\sigma})^{2}}} = 0$$ The first is not equal to zero and exponentioal. Therefore, $$\\sum_{i}{\\frac{x_i}{\\sigma^2}} - \\frac{2n\\mu}{2\\sigma^2} = 0$$ $$\\sum_{i}{\\frac{x_i}{\\sigma^2}} = \\frac{2n\\mu}{2\\sigma^2}$$ $$\\sum_{i}{x_i} = \\frac{2n\\mu}{2}$$ $$\\mu = \\frac{\\sum_{i}{x_i}}{n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $\\sigma$, we take the log of it, then find the maxima with regards to the differential at $\\sigma$, this gives:\n",
    "$$\\frac{\\delta}{\\delta \\sigma}\\log(P(data | \\sigma, \\mu)) = \\frac{\\delta}{\\delta \\sigma}(n\\log(\\frac{1}{\\sigma\\sqrt{2\\pi}}) -\\frac{1}{2}\\sum_i{(\\frac{x-\\mu}{\\sigma})^{2}}) = -\\frac{n}{\\sigma^2\\sqrt{2\\pi}}\\times(\\sigma\\sqrt{2\\pi}) + \\frac{\\sum_i{(x-\\mu)^2}}{\\sigma^3} = -\\frac{n}{\\sigma} + \\frac{\\sum_i{(x-\\mu)^2}}{\\sigma^3} = 0$$\n",
    "$$\\sigma^2n = \\sum_{i}{(x-\\mu)^2}$$\n",
    "\n",
    "This result tells us that the mean and variance that will produce maximum likelihood would be the ones from the observed dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
